---
title: "Homework 5"
author: "Nidhi Patel"
date: "11/18/2020"
output: github_document
---
```{r}
library(tidyverse)
library(rvest)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.height = 6,
  out.width = "90%")

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_color_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1

#### Read in Data + make vars we want

```{r}
homicide = read_csv("./data/homicide-data.csv") %>% 
  unite(city_state, c("city", "state"), sep = "_") %>% 
  mutate(
    solved = ifelse(disposition == "Closed by arrest", rep(TRUE), FALSE))
```

This dataset contains `r ncol(homicide)` variables with `r nrow(homicide)` observations.  Each homicide is distinguished by an unique id, contains basic demographic information about the victim, the location and reported date of the murder, and whether an arrest was made. 

#### summarize

```{r}
resolved_df = 
  homicide %>%
  group_by(city_state) %>% 
  summarize(
    tot_hom = n(),
    unsolved_hom = sum(solved == "FALSE")) %>% 
  filter(city_state != "Tulsa_AL")
```

#### `prop.test` proportions

```{r}
prop.test(
  resolved_df %>% filter(city_state == "Baltimore_MD") %>% pull(unsolved_hom),
  resolved_df %>% filter(city_state == "Baltimore_MD") %>% pull(tot_hom)
) %>% #you have to put the actual numbers in the prop test fn. 
  broom::tidy()
```

#### iterate this for every city; make a df for the estimated proportions

```{r}
estimate_prop = 
  resolved_df %>% 
  mutate(
    prop_tests = map2(.x = unsolved_hom, .y = tot_hom, ~prop.test(x = .x, n = .y)),
    tidy_tests = map(.x = prop_tests, ~broom::tidy(.x))
) %>% 
  select(-prop_tests) %>% 
  unnest(tidy_tests) %>% 
  select(city_state, estimate, conf.low, conf.high)
```

#### plot estimates and CIs

```{r}
estimate_plot = estimate_prop %>% 
  mutate(
    city_state = as_factor(city_state),
    city_state = fct_reorder(city_state, estimate)
  ) %>% 
  ggplot(aes(x = city_state, y = estimate, color = city_state)) +
  geom_point(alpha = 3) +
  geom_errorbar(aes(ymax = conf.high, ymin = conf.low)) +
  theme(legend.position = "none", axis.text.x = element_text(angle = 90)) +
  labs(title = "observations of control and experimental arms over 8 weeks"
  )

estimate_plot
```

## Problem 2

Create a df with all the patients. 

#### make the dataframe and tidy

```{r}
study_df =
  tibble(
    files = list.files("data/data/"),
    path = str_c("data/data/", files)
  ) %>% 
  mutate(data = map(.x = path, ~read_csv(.x))) %>% 
  unnest(data) %>% 
  mutate(rename = str_replace(files, ".csv", "")) %>% 
  separate(rename, into = c("arm", "sub_id"), sep = 3) %>% 
  mutate(sub_id = str_replace(sub_id, "_", "")) %>% 
  pivot_longer(
    week_1:week_8,
    names_to = "week",
    names_prefix = "week_",
    values_to = "obvs"
  ) %>% 
  select(arm, sub_id, week, obvs)
```

#### Spagetti plot

```{r}
study_df %>% 
  group_by(arm, sub_id) %>% 
  ggplot(aes(x = week, y = obvs)) +
  geom_point(aes(color = arm)) +
  geom_path(aes(group = sub_id, color = arm))
```
There are some visual differences in the control and experimental outcomes of this longitudinal study. Both control and experimental observations consistently varied between -1.25 and 2.75.  Throughout the weeks, the experimental observations trended upwards and the control observations remained relatively the same.  The control group looks like it trended slightly downward, but it is difficult to tell whether this is the true effect, or due to a smaller sample size.

## Problem 3

Simulation to explore power of a one sample t-test!!

#### Write the function for true mean = 0. Save in tibble

```{r}
ttest_sim = function(mu) {
  sim_data = 
    tibble(
    x = rnorm(mean = 0, n = 30, sd = 5),
    )
  
  ttest = t.test(sim_data, mu = 0, alpha = 0.05)
  
  results_sim0 = tibble(
    pvalue = ttest[["p.value"]],
    mean = ttest[["estimate"]]
  )
}
```
 
#### Reiterate function

```{r}
sim_results =
  tibble(true_mu = c(0:6)) %>% 
  mutate(
    output_lists = map(.x = true_mu, ~rerun(5000, ttest_sim(mu = .x))),
    ttest_df = map(output_lists, bind_rows)
  ) %>% 
  select(-output_lists) %>% 
  unnest(ttest_df)
```

#### Proportion of null rejected (power)

```{r}

proportion = 
  sim_results %>% 
  filter(pvalue < 0.05) %>% 
  group_by(true_mu) %>% 
  mutate(
    rejected = n(),
    power = rejected / 5000) %>% 
  ggplot(aes(x = true_mu, y = power)) +
  geom_point() +
  labs(
    title = "power by true mean",
    xlab = "true mean",
    ylab = "power"
  )
proportion
```

This outcome is very surprising to me.  I would expect mu = 6 to be rejected more and have a higher power than all the other mu's. I would expect all others to have decreasing power. 

#### 